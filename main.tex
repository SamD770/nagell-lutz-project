\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Elliptic Curves and the Nagell-Lutz theorem:\\a guided reinvention}
\author{Samuel Dauncey}

\begin{document}
\maketitle

\begin{abstract}
    
"Number theory has an annoying habit: the field produces, without effort, innumerable problems which have a sweet, innocent air about them, tempting flowers; and yet... number theory swarms with bugs, waiting to bite the tempted flower-lovers who, once bitten, are inspired to excesses of effort!" - Barry Mazur
\end{abstract}

\section{Introduction and Motivation}

\subsection{An innocent-looking problem}

Suppose one wanted to find all solutions to the polynomial equation:\\

$3 X^3 +  2 X Y^2 + 2 Y^3 = Z^3$ \quad For integers $X$, $Y$ and $Z$. \\

 One may realise that, given a solution; say $(X, Y, Z) = (1, 2, 3)$, one can see that we can generate infintely many more solutions $(X, Y, Z) = (2, 4, 6), \; (3, 6, 9), \; \dots \; (n, 2n, 3n) \; \dots $. This property of our equation is special, it is called \emph{homogeneity} and stems from the fact that if we sum up the powers of $X$, $Y$ and $Z$ in each of the terms of our equation, we get the same integer (in this case, three). \\
 
 Finding solutions to homogeneous equations is of special importance to number theorists, examples including the Fermat equations $X^m + Y^m = Z^m$. \\
 
 In essence, we can think of each of these infinite sets of solutions as all part of the same solution, and we can see that, if we view our solutions as coordinates in $R^3$, each one of our infinite sets of solutions can be viewed as a line going through the origin and and a point with integer coordinates. Dividing our original equation by $Z$, we can see that our problem is equivalent to finding the rational solutions to the equation:\\
 
 $3x^3 + 2xy + 2y^3 = 1$\\
 
With rational solution $(x, y) = (\frac{m}{n}, \frac{p}{q})$ being converted into $(X, Y, Z) = (m, p, nq)$ and integer solution $(X, Y, Z)$ being converted into $(\frac{X}{Z}, \frac{Y}{Z})$. However, note that this conversion isn't well-defined when $Z = 0$, so we still have to consider the integer solutions to $3 X^3 +  2 X Y^2 + 2 Y^3 = 0$. However; as this is also a homogeneous polynomial equation, we can repeat our process, this time by dividing by $Y$ to see we want to find solutions to: \\

$3 x^3 + 2 x + 2 = 0$ \quad for rational $x$ and $X^3 = 0$ for integer $X$\\

Hence, we can see that there is a one-to-one correspondence between the "lines" of integer solutions to $3 X^3 +  2 X Y^2 + 2 Y^3 = Z^3$ and rational solutions to  $3x^3 + 2xy + y^3 = 1$, \quad $3 x^3 + 2 x + 2 = 0$, and $X^3 = 0$. Thinking back to our visualisation of our solutions to our integer equation as lines, we can see that our first division resembles looking at the intersection of the plane $Z = 1$ and our solution lines, and the fact that we could recursively apply this procedure is a hint that the \emph{projective space} we are working in has some kind of recursive structure.

Now, we can trivially solve $X^3 = 0 $ to see that $X = 0$ is the only solution (corresponding to the solution $(X, Y, Z) = (0, 0, 0)$). Slightly more difficult is the rational solutions to $3x^3 + 2 x + 2 = 0$; Gauss's Lemma tells us that any solution in it's lowest terms $x = \frac{m}{n}$ must have $m$ dividing $2$ and $n$ dividing $3$, however we can see that the only candidates this leaves, $x = +-\frac{2}{3}$ do not solve the equation; so we have no solutions of the form $(X, Y, 0)$ with non-zero $Y$. Hence, we can see that the only thing stopping us from solving our starting problem is finding all the rational solutions to  $3x^3 + 2xy + y^3 = 1$; unfortunately, this turns out to be alot harder. \\

These solutions form an \emph{algebraic curve} when visualised in the $x,y-$plane, and through analysing this curve geometrically we will be able to get some description of our solution.\\

Note that, given two points $(x_1, y_1)$ and $(x_2, y_2)$ on a degree-3 algebraic curve defined by $f(x, y) = 0$, we can find a third point $(x_3, y_3)$ on the curve by projecting a line $\alpha x + \beta y + \gamma = 0$ through them and looking at the intersection with the curve (in general*). On top of this, when we solve these simultaneous equations by eliminating one variable we get two cubics for the $x$ and $y$ coordinates, $a_3 x^3 + a_2 x^2 + a_1 x + a_0 = 0$ , \quad $b_3 y^3 + b_2 y^2 + b_1 y + b_0 = 0$. We know that the sums $x_1 + x_2 + x_3 = -\frac{a_2}{a_3}$ and $y_1 + y_2 + y_3 = -\frac{b_2}{b_3}$ are satisfied; so if $x_1$, $x_2$ and our coefficients are in some field $F$, $x_3$ must also be in $F$; and likewise for our $y$ coordinates, this means that, given a pair of rational solutions we can get another rational solution by projecting a line. For example,


\[ <example> \]

* the case where $a_3$ or $b_3$ are zero corresponds to the case where our line meets our curve asymptotically, or "at infinity", and we will see more about this when we go into projective geometry.\\ 

The first theorem I will explain is Mordell's theorem, which tells us that we can take a finite set of rational points on our curve and, by projecting lines through them, can get every other rational point on our curve.\\

If we now imagine our points $(x_1, y_1)$ and $(x_2, y_2)$ slowly getting closer and closer to each other on our curve, we may also notice that we could just take one point, draw the tangent from it, and get another rational point. For example, 

\[<example>\]

The second theorem we will prove is the Nagell-Lutz theorem, which tells us how to find the points will eventually "loop" if we continually apply this process of taking a tangent and seeing where it intersects the curve. For example,

\[<example>\]

After looking deeper into the theory of cubic curves, we will see why these looping points are of particular interest. But first, a reader may be wondering: why are we focusing on cubic curves? Why not try and solve the general case of n-degree curves?

\subsection{Why cubic plane curves?}

one variable:

-pretty much fully solved?

two variables:

- degrees 1 and 2 solved

- degree 3 much harder (not all questions answered)

three variables:

- ???

Yuri Matiyasevich's negative solution to Hilbert's tenth problem: no algorithm (including the algorithm of all human mathematicians) will be able to determine whether or not a given diophantine equation has solutions.

\subsection{Assumed prior knowledge}

- Algebra: knowledge of a group, ring and field

\newpage

\section{Projective geometry}

\subsection{Homogeneous Coordinates}

In the introduction section, I hinted at the idea that we can think of linearly related solutions, such as $(1, 2, 3)$ and $(2, 4, 6)$ to our homogeneous equation  as one line in $R^3$ and we can make this rigorous by defining a new kind of space. We kind of already did this when we divided by $Z$, but this feels unnatural because it is breaking the symmetry of our equation between $X$, $Y$ and $Z$. We will see later that this kind of space is called \emph{projective space} and when we do geometry on this space it is called \emph{projective geometry}, hence the name of this section.\\

We want to define a \emph{point} such that all the solutions $(t, 2t, 3t)$ are considered to be the same, just as when we divided through by $Z$ in our introduction. So it makes sense to say a point in projective space as a ratio between the X, Y and Z coordinates, :\\

We denote $P = [X : Y : Z] \in P_R^2$ for real numbers $X$, $Y$ and $Z$ which are called the \emph{homogeneous} coordinates of $P$;\\

where two points are said to be equal, ie $[X : Y : Z] = [X' : Y' : Z']$ if and only if we can find a $t \in R$ satisfying $X = tX', Y =  tY'$ and $Z = tZ'$\\

Unfortunately, this on it's own is not a well-defined equivalence relation; every point is equal to $[0 : 0 : 0]$. To fix this, we simply ban this point and say if  $[X : Y : Z] \in P_R^2$  then one of $X$, $Y$ and $Z$ is non-zero. It is relatively straightforward to now mentally check that this definition of equality satisfies reflexivity, symmetry and transitivity.\\

Note that, if you view the homogeneous coordinates $X$, $Y$ and $Z$ as a point $(X, Y, Z)$ in $R^3$ then our \emph{points} in $P_R^2$ (the equivalence classes of coordinates which give equal points) can be visualised as \emph{lines} going through the origin in $R^3$. Hence, it makes intuitive sense that our \emph{lines} in $P_R^2$ could be visualised as \emph{planes} containing the origin in $R^3$. This intuition gives us the definition of a line in $P_R^2$:\\

A line in $P_R^2$ is the set of points $[X : Y : Z]$ where $AX + BY + CZ = 0$ for some fixed $A$, $B$ and $C$. \\

Note our definition of a line is well defined as  $AX + BY + CZ = 0$ iff  $A(tX) + B(tY) + C(tZ) = 0$ for non-zero $t$. This geometrical intuition gives us an interesting property of lines in $P_R^2$: \\

Two distinct lines in $P_R^2$ intersect at exactly one point. For example, say we have two lines $AX + BY + CZ = 0$ and $\Bar{A}X + \bar{B}Y + \bar{C}Z = 0$. We can solve these equations simultaneously by putting them in a matrix-vector product:\\

$$ \begin{bmatrix}
A & B & C \\
\Bar{A} & \Bar{B} & \Bar{C} 
\end{bmatrix} 
\begin{bmatrix}
X \\
Y \\
Z \\
\end{bmatrix} 
= \vec{0}
$$

From this we can see that, if the two lines are distinct, then $A  B  C$ and
$\Bar{A}  \Bar{B}  \Bar{C} $ will be linearly independent, as if they weren't, we would be able to reduce their defining equations onto each other. Hence our matrix will have rank 2 and so by the rank-nullity theorem we will have one linearly independent solution for $X$, $Y$ and $Z$, corresponding to our point of intersection in $P_R^2$. This property of lines in $P_R^2$ is different to, say, $R^2$, where parallel lines intersect nowhere.
\\
When we divided by $Z$ in our introduction, we took each point in $P_R^2$ and mapped it to a point in $R^2$, barring the points where the $Z$ coordinate was $0$. The obvious way to map points in $P_R^2$ onto a surface is to look at projecting them onto the unit sphere using the angles as coordinates, For example mapping $[1 : 2 : 3]$ to the point $(arcsin(), arccos())$. The problem with this approach is that this takes a point with rational coordinates and maps it to a point without rational coordinates; meaning it isn't very useful for us. Instead, we have to suffice by projecting our projective plane onto a flat screen.

- recursive definition

 Note that in this section I used the real numbers, $R$ as the field that we were working over. However, the proofs used no special properties about the real numbers, hence we could replace $R$ with any field $F$ and get the same results. In general, we call $P_F^2$ the \emph{projective plane over the field} $F$,  alot of algebraic geometry is concerned with $P_C^2$ for instance, however for us it suffices to know that $P_Q^2$ is well defined.

\subsection{Projective Transformations}



\subsection{The Wierstrauss normal form}

Let us start with the cubic curve defined in non-homogeneous coordinates by:

\[ x^{3} - 4 x^{2} y - 4 x^{2} - 2 x y^{2} - 2 x y - 3 y^{3} - 5 y^{2} - 2 y\ =\ 0 \]

We will show that this curve can be transformed, using only projective transformations, into the much simpler \emph{elliptic curve}:

\[y^2 = x^3 - x + 1\]

The first key is to see that our cubic curve has a point of multiplicity $3$ at [0: -1: 1], whereas our elliptic curve has a point of multiplicity $3$ at [0: 1: 0]. Hence, it makes sense that we should find a transformation that maps the former point to the latter point. A straightforwards transformation we could pick is:

\[ T_1 = \begin{bmatrix}
    1 & 0 & 0\\
    0 & -1 & 0\\
    0 & 1 & 1
\end{bmatrix},
\quad
T_1: <X, Y, Z> \; \mapsto \; <X, -Y, Y + Z>
\]

Subbing this to our equation gives:

\[x^{3} - 4 x^{2} + 2 x y - y^{2} + 2 y = 0\]

Equivalently:

\[y^2 - 2 x y - 2y = x^3 + 4x^2\]

As we see, our curve has been significantly simplified, however it still has some pesky $xy$ and $y$ terms that means that it doesn't have the nice symmetry about the $y$ axis that our target curve has. To get it in the desired form, we complete the square of the right hand side to see how we should transform our y coordinate.

\[(y - (x + 1))^2 - (x + 1)^2 = x^3 + 4x^2\]

Hence, it makes sense to pick a transformation that maps $y - (x + 1) \mapsto y$. One good candidate is:

\[ T_1 = \begin{bmatrix}
    1 & 0 & 0\\
    -1 & 1 & -1\\
    0 & 0 & 1
\end{bmatrix},
\quad
T_2: <X, Y, Z> \; \mapsto \; <X, Y - X - Z, Z>
\]

After this transformation, our curve has equation:

\[y^{2} = x^{3} - 3 x^{2} + 2 x  + 1\]

This curve is already in the "Weierstrass normal form"; however we can simplify it even further. Namely, we know that the $x^2$ term ($-3$) is the sum of the roots of the cubic on the right, so if we apply a transformation that maps $T_3: x \mapsto x - 1$. This gives us the final equation of our curve:

\[y^{2} = x^{3} - x  + 1\]

This process can be replicated for \emph{any} cubic curve where we have a point of multiplicity three, which may be projectively transformed into an elliptic curve of the form:

\[y^2 = x^3 + bx + c\]

While this is interesting, it is not clear why it is important. The first thing to note is that we can combine our projective transformations into one  projective transformation $T = T_3 T_2 T_1$ which maps rational points on our original cubic curve $C$ to rational points on our elliptic curve $E$. As all projective transformations are invertible, this means that $T$ is in fact a bijection, so any rational point on $C$ can be converted into a rational point on $E$ and vice versa. On top of this, we know that projective transformations map lines to lines, meaning that for any points $P$ and $Q$ on $T(P *_C Q) = T(P) *_E T(Q)$. Extending this a bit further, it is not tricky to see that it must be the case that:

\[T(P +_C Q) = T(P) +_E T(Q)\]

Hence, we can see that not only is T a bijection between the rational points of our curve, but it is in fact an \emph{isomorphism} between the groups of rational points. This means that anything we discover about the group of rational points of our simpler elliptic curve can be extended to all cubic curves, and we will see it will be easier to work with elliptic curves, mainly because it is much easier to add points on elliptic curves.

\subsection{Groups over Cubic Curves}

Let $C(F)$ be a cubic curve working in some field $F$

As we saw:

define $P * Q \in C(F)$ to be the third point on $C(F)$,

have $P * Q = Q * P$

and $(P * Q) * Q = P$

Is $(C(F), *)$ a group? Unfortunately not; it is not hard to mentally verify that a unique identity element doesn't exist and that associativity won't hold.

For three points, $P$, $Q$ and $R$ on our curve $C$ Write $P - Q - R$ to mean these three points are colinear, this notation helps us clear up the fact that these six statements are equivalent:

$P * Q = R, P * Q = R, P * R = Q,  Q * R = P$

if $A - B - C$ and $D - E - F$ and $A - D - G$ and $B - E - H$

then $C * F = G * H$

If we slightly abuse our new notation, our theorem becomes:

if
$
\\
A - B - C \\
D - E - F \\
H - I
$\\
then, for some $J \in C(F)$:
$
\\
A - B - C \\
D - E - F \\
H - I - J
$

Although the notation makes this look intuitive, it is not at all obvious. 
Why should the line defined by $C$ and $F$ and the line defined by $H$ and $J$ intersect with the curve at the same point? 

Three cubic curves that meet at eight points $P_1 \dots P_8$ will also all meet at a ninth point $P_9$.

let v be the vector:

$
\begin{bmatrix}
X^3 \\
Y^3 \\
Z^3 \\
\end{bmatrix} 
$

-why is the group law the way it is?

- show ((A * B) * O) * C = A * ((B * C) * O) ?

therefore, if A + B = (A * B) * O then (A + B) + C = A + (B + C)

\newpage

\section{Mordell's theorem}

In this section we will go over a theorem originally proved by Louis Mordell in 1922, which states that the group of rational points over any elliptic curve $C(Q)$ is finitely generated; ie there exists some finite subset of $C(Q)$ such that every element of $C(Q)$ can be written as the sum of points in this subset. This tells us alot about the group's structure; namely using the fundamental theorem of finitely generated abelian groups it tells us that:

\[C(Q) \cong Z^n \times C(Q)_{tors}\]

Where $C(Q)_{tors}$ is the finite subgroup of \emph{torsion points} of $C(Q)$ (the points of finite order) and $n$ is called the \emph{rank} of our Elliptic curve. The question of what possible ranks elliptic curves can have is still an open question; with no clear conjecture as to what the answer should be. A similar proof was extended by Wiel to the Mordell-Wiel thoerem for his doctoral thesis; this theorem states that all abelian varieties (of which elliptic curves are a type) have finitely generated sets of rational points.\\

For brevity, I have emitted the proof for one of the key lemmas in the theorem (namely that there is a finite number of cosets of $2C(Q)$ in $C(Q)$) because fully proving it would require a significant detour into complex analysis. Other lemmas I have only partially proved; hoping to give an intuition as to why the fact is true rather than getting into the weeds of writing out a full proof - which would make this report much longer than I am targeting. Full proofs for all these lemmas can be found in Silverman.\\

One thing one will notice by playing around with the addition law is that, as we add points, the points seem to get progressively more "complex". For instance: <example>
Hence, it makes sense that our generating set would be comprised of points of low complexity (and as the generating set is finite, at least \emph{bounded} complexity), to prove our theorem about $C(Q)$ being finitely generated; it makes sense to do two things;\\

1. prove that the number of points below a certain bound of complexity is finite \\

2. show that every point can be decomposed into a sum of lower-complexity points \\

To do this, we define the \emph{height} of a rational number $q = \frac{m}{n}$ as the maximum of it's numerator and denominator written in it's lowest terms:

\[ H(q) = H(\frac{m}{n}) = max(|m|, |n|) \text{where m and n are coprime.} \]

We will see that we can adapt this notion of height of rational numbers into a concrete measure of complexity for our points. But first, we need to examine height in more detail.

\subsection{The properties of height}

To get familiar with the height function, one can mentally verify that the height function sastisfies the following upper bounds:\\

- $ H(pq) \ \leq \ H(p)H(q) $\\

- $ H(p + q) \ \leq \ 2H(p)H(q) $\\

- $ H(p^n) \ = \ H(p)^n $ \\

As our formulae for adding points involves substituting their coordinates in for polynomials; it makes sense to examine how the height works with polynomials. Intuitively, it makes sense that the the size numerator or denominator of the result of a polynomial will grow roughly with the size of the numerator or denominator of the input raised to the degree of the polynomial; which we can express with the following lemma:\\

If $f$ is a polynomial of degree $n$, then there exist constants $K_l$ and $K_u$ only depending on $f$ such that, for all $x$:

\[ K_l (H(x))^n \leq H(f(x)) \leq K_u (H(x))^n \]

The proof of the upper bound is relatively straightforwards using our upper bound properties of height:

\begin{align*} 
H(f(x)) &= H(a_n x^n + a_{n-1}x^{n-1} + \dots + a_1 x + a_0)\\
&\leq 2H(a_n x^n + a_{n-1}x^{n-1} + \dots + a_1 x)H(a_0)\\
&\leq 2H(x(a_n x^{n-1} + a_{n-1}x^{n-2} + \dots + a_1))H(a_0)\\
&\leq 2H(x)H(a_n x^{n-1} + a_{n-1}x^{n-2} + \dots + a_1)H(a_0)\\
&\leq 4H(x)H(a_n x^{n-1} + a_{n-1}x^{n-2} + \dots)H(a_1)H(a_0)\\
&\dots\\
&\leq 2^n (H(x))^n H(a_n)H(a_{n-1})\dots H(a_1)H(a_0)
\end{align*} 

then, we can see that:

\[ H(f(x)) \leq K_u H(x)^n \quad \text{with} \quad K_u = 2^n H(a_n)H(a_{n-1})\dots H(a_1)H(a_0) \]

Proving the lower bound is trickier, mainly because for arbitrary $p$ and $q$ we cannot put lower bounds on $H(pq)$ or $H(p + q)$ based solely on $H(p)$ and $H(q)$. Instead, we have to write $x = \frac{\alpha}{\beta}$ as a fraction in it's lowest terms. Then, we can see that:

\begin{align*}
    H(f(x)) &= H(f(\frac{\alpha}{\beta}))\\
            &= H(\frac{1}{\beta^n}(a_n \alpha^n + \alpha_{n-1} \beta x^{n-1} + \dots + a_1 \alpha \beta^{n-1} + a_0 \beta^n))\\
            &= max(|\beta^n|, |\beta^n f(\frac{\alpha}{\beta})|)\
\end{align*}

On the last line, we used the fact that both $\beta^n f(\frac{\alpha}{\beta})$ and $\beta^n$ are integers, and that $\beta^n f(\frac{\alpha}{\beta}) - \alpha^n \equiv 0 \quad (\bmod{\beta})$ but $\alpha \not\equiv 0 \quad (\bmod{\beta})$, so $gcd(\beta^n f(\frac{\alpha}{\beta}), \beta) = 1$. Now, as the max of two numbers is always greater than the average, we can see that:

\begin{align*}
    H(f(x)) & \geq \frac{|\beta^n| + |\beta^n f(\frac{\alpha}{\beta})|}{2}\\
    &\text{so}\\
    \frac{H(f(x))}{H(x^n)} &\geq \frac{|\beta^n| + |\beta^n f(\frac{\alpha}{\beta})|}{2 max(|\alpha^n|,|\beta^n|)}\\
                        &= \frac{1 + |f(\frac{\alpha}{\beta}|)}{2 max(1, |\frac{\alpha^n}{\beta^n}|)}\\
                        &= \frac{1 + |f(x)|}{2 max(1, |x|^n)}
\end{align*}

Hence, all we need to do to prove our lemma is show that the function: $g(x) = \frac{1 + |f(x)|}{2 max(1, |x|^n)}$ has positive lower bound $g(x) \geq K_l > 0$. Note that this function is continuous, so it's image is a interval in $R$. Let $K_l = inf(im(g)$, it suffices to show that $K_l > 0$. Note that $g$ is positive, so $K_l \geq 0$ so the only case we have to deal with is when $K_l = 0$. in this case, $g$ gets arbitrarily close to $0$ so we must be able to find a convergent sequence $(x_n)$ such that $g(x_n) \rightarrow K_l = 0$. \\

- In the case where $(x_n)$ converges to some real number $r$ we can see that as $g$ is continuous, $g(r) = 0$, which we can see is a contradiction as $g$ is a strictly positive function.\\

-In the case where $(x_n)$ converges to $\infty$, we can see that $g(x) \rightarrow \frac{|a_n|}{2}$, which must be non-zero as $a_n$ is non-zero, so we also derive a contradiction.\\

Thus, conclude the proof of our lower bound:

\[ K_l H(x)^n \leq H(f(x)) \]

Notationally, it becomes easier to examine the log-height, denoted with a small $h$: $h(x) = ln(H(x))$. Then our lemma becomes:

\[ n h(x) + k_l \leq h(f(x)) \leq n h(x) + k_u \]

Applying this lemma to our curve, we can see there exists constants $k_1$ and $k_2$ such that if $(x, y)$ is a point the curve: $y^2 = f(x) = x^3 + ax^2 + bx + c$:

\[ \frac{3}{2} h(x) + k_1 \leq h(y) \leq \frac{3}{2} h(x) + k_2 \quad \text{as} \quad h(y) = \frac{1}{2}h(f(x)) \]

Hence, for a point $P = (x_P, y_P) \in C(Q)$ it makes sense to define the complexity of $P$ as the height of it's $x$ coordinate, as the height of it's $y$ coordinate is linked to the height of it's $x$ coordinate and it is easier to compute the $x$ coordinates of $2P$ and $P + Q$. From now on, we will denote $h(P) = h(x_P)$ to be the height of the \emph{point} $P$. By convention, we also set $h(0) = 0$.\\

Before doing this, we will prove a lemma that will be key to our theorem:\\

For any given curve $C(Q)$ and upper bound $B$, there are only finitely many points $P \in C(Q)$ such that $h(P) < B$.\\

The proof is very simple; the trick is to think of the rational numbers as a plane where the denominator is plotted on the x axis and the numerator is plotted on the y axis. Consider the function $g: Z \times N \rightarrow Q$ where $g: (m, n) \mapsto \frac{m}{n}$. We can see that $g$ is surjective the set of inputs to $g$ which give an output with height less than $B$ is a rectangle, with one side length $2B + 1$ (as there are $2B + 1$ choices for the numerator) and the other side length $B$ (as there are $B$ choices for the denominator). Hence, there are at most $B(2B + 1)$ distinct rational numbers with height less than $B$. However, for a given curve $C(Q)$, there are at most two points with a given rational $x$ coordinate, hence there are at most $2B(2B + 1)$ points of height less than $B$\\


To bring this back to what we said in our introduction, this means all we need to do to prove $C(Q)$ is finitely generated is to show that there is a set of points that generates $C(Q)$ and has bounded height; as then this set must be finite. Before we do this however, we need to examine how height interacts with the group law; as we need to introduce the notions of adding points with our height function for any hope of such a proof working.\\

\subsection{Examining how height interacts with the group law}

Let $P = (x_P, y_P)$ be any point on an Elliptic Curve $C(Q)$. We will first examine how $h(2P)$ and $h(P)$ relate.\\

Recall our duplication formula for finding $x_{2P}$ in terms of $x$:

\[x_{2P} = \frac{f'(x_P)^2}{4 f(x_P)} - a - 2x_P = \frac{x_P^4 - 2bx_P^2 - 8cx_P + b^2 - 4ac}{4(x_P^3 +x_P^2 + bx_P + c)}\]

In the first section, we derived a result about the height of polynomials in terms of the height of the input variable; we will see that we can derive a similar result for the \emph{quotients} of polynomials as well. Namely, if $p(x)$ is a polynomial of degree $n$ and $q(x)$ is a polynomial of degree less than $n$ without common roots to $p$ (to prevent cancellation), then the height of $\frac{p(x)}{q(x)}$ grows roughly with the height of $x^n$. In precise terms there exist $k_l$ and $k_u$ dependent only on $p$ and $q$ such that for all $x$;

\[n h(x) + k_l \leq h \left( \frac{p(x)}{q(x)} \right) \leq n h(x) + k_u \]

The proof is similar to the proof for just one polynomial; however it is much longer so I have not included it (One can see Section 3.3 of Silverman for the full proof). Applying this to our duplication formula gives:

\[4h(P) + k_l \leq h(2P) \leq 4 h(P) + k_u\]

This is our first result about the height of points under the group law. Now, we will let $Q = (x_Q, y_Q)$ be a point on $C(Q)$ and see how $h(P + Q)$ relates to $h(P)$.

\begin{align*}
    x_{P + Q} &= \lambda^2 - a - x_P - x_Q\\
              &= \frac{(y_P - y_Q)^2 - (x_P - x_Q)^2(a + x_P + x_Q)}{(x_P - x_Q)^2}
\end{align*}

Note that if we replace $y_P^2$ with $x_P^3 + a x_P ^2 + b x_P + c$ and eliminate then our numerator can be reduced to:

\[x_{P + Q} = \frac{A y_P - (B x_P^2 + C x_P + D)}{(x_P - x_Q)^2}\]

Where $A$, $B$, $C$ and $D$ can be written in terms of $a$, $b$, $c$, $x_Q$ and $y_Q$. As we know $y_P \approx x_P^{\frac{3}{2}}$, it makes sense to say that the numerator is roughly quadratic in $x_P$. Although we will not fully prove this, using the fact about the height of quotients of polynomials above we are lead to think that $H(x_{P+Q}) \approx K_Q H(x_P)^2$ where $K_Q$ depends on $Q$ as well as the coefficients of our curve. This turns out to be correct, with the final result being that there is a $k_Q$ dependent on $Q$ such that for all $P \in C(Q)$:

\[h(P + Q) \leq 2h(P) + k_Q\]

Again fully proving this - while not requiring particularly advanced mathematics - would take a couple pages of working; and this can be seen in Section 3.4 of Silverman if one wishes.

\subsection{Proving the descent theorem}

Thus far, we have three results that we will use in our proof:\\

- For any elliptic curve $C(Q)$ and  real number $B$, the number of points $P \in C(Q)$ such that $h(P) \leq B$ is finite.\\

- We have a lower bound $h(2P)$, namely that there is a $k$ only dependent on $C(Q)$ such that for any point $P \in C(Q)$ :

\[ 4h(P) - k \ \leq \ h(2P) \]

- We have an upper bound on $h(P + Q)$, namely that for all $Q \in C(Q)$ there is a $k_Q$ independent of $P$ such that:

\[ h(P + Q) \ \leq 2h(P) \ + k_Q \]

- As mentioned in the introduction to this section, there is one final lemma needed to prove Mordell's theorem; namely that there is a finite set $A = {A_1, A_2 ... A_N}$ such that every $P \in C(Q)$ can be written as :

\[ P = 2Q + A_i \quad \text{for some} \ i \]

This is equivalent to the statement that the image of the mapping $P \mapsto 2P$ (which turns out to be a subgroup of $C(Q)$) has a finite number of cosets in $C(Q)$. As already mentioned, Mordell proved this using some interesting properties of the curve $C(C)$, and unfortunately I cannot go over the proof here as it it too long.\\

These four lemmas can be brought together to prove there is a bound $B \in R$ such that every $P \in C(Q)$ with $h(P) < B$ can be written as a sum of points $P = P_1 + P_2 + P_3 + \dots P_N$ such that $h(P_i) < h(P) - 1$. Recursively applying this to our points $P_i$, we see that we can eventually write $P$ as a sum of points in the finite set.\\

For a given $B$, let:

\[ C(Q)_B = \{P \in C(Q) | h(P) \leq B\} \]

We will prove this now. Let $P_0 \in C(Q)$. We know we can find an $A_i \in A$ and $Q$ in $C(Q)$ such that:

\[P_0 = A_i + 2P_1 \]

equivalently:

\[ 2P_1 = P_0 - A_i \]

Applying our lower and upper bounds we see that:

\[ 4h(P_1) - k \quad \leq \quad  h(2P_1) =  P_0 - A_i  \quad  \leq  \quad  2h(P_0) + k_{-A_i} \]

Hence:

\[ h(P_1) \ \leq \ \frac{1}{2}h(P_0) + \frac{1}{4} (k + k_{-A_i}) \]

Hence, if we let $k_A = \max_{A_i \in A}(k_{-A_i})$, which we know exists as $A$ is finite, we can see that if $\frac{1}{4}(k + k_A) \leq \frac{1}{2}h(P_0) - 1$ then:

\[ h(P_1) \leq \frac{1}{2}h(P_0) + \frac{1}{4} (k + k_{-A_i}) \leq \frac{1}{2}h(P_0) + \frac{1}{2}h(P_0) - 1 \leq h(P_0) - 1 \]

We can also see that the restriction $\frac{1}{4}(k + k_A) \leq \frac{1}{2}h(P_0) - 1$ can be turned into $h(P_0) \geq B$ where $B = \frac{1}{2}(k + k_A) + 2$. we have hence proven that: if $P_j \in C(Q)$ then either: $h(P_j) \leq B$ or we can find a $P_{j + 1}$ such that $h(P_{j + 1}) \leq h(P_j) - 1$ and $P_j = 2P_{j+1} + A_i$ for some $A_i \in A$.\\

We can apply this reasoning inductively to show that, for any given $P_0 \in C(Q)$, we can eventually find a $P_N \in C(Q)$ and $A_{i_1}, A_{i_2} \dots A_{i_N} \in A$ such that:

\[ P_0 = 2^N P_N + A_{i_1} + 2 A_{i_2} + \dots + 2^{N-1}A_{i_N} \]

\[ \text{and} \ h(P_N) \ \leq B. \ (\text{equivalently}, \ P_N \in C(Q)_B) \]

Hence, we can see that our two sets $C(Q)_B$ and $A$ can generate $C(Q)$; however, as $C(Q)_B$ and $A$ are finite, their union is finite, so $C(Q)$ is finitely generated.


\newpage

\section{The Nagell-Lutz theorem}

\subsection{General idea and motivation}

For this section, knowledge and familiarity with the concepts of rings and ideals asssumed\\

The Mordell-Wiel theorem gave us information about the structure of the group of rational points; however the problem of finding the rank or the generating set for some curve $C$ is still not fully solved. Thankfully, the other component of our group, the torsion subgroup, is much better understood, and in the following chapter we will go through a theorem that fully describes how to find all of it's points for any given curve C: the Nagell-Lutz theorem.\\

In general, points seem to increase their "complexity" when we add them. For instance, in our proof of the Mordell-Wiel theorem, we showed that the amount of points under some bound of the complexity measure of height was finite, and we could find a bound that contains all of the generating elements. This means that, if P is some generating element then the height of P must increase without bound, ie the sequence $h(nP)$ for natural $n$ is unbounded. This is in contrast to our points in the torsion group, where $h(nP)$ is periodic and therefore must be bounded. Hence, it seems like a good method to find the torsion points of our curve would be to look for points for which $h(nP)$ is bounded.\\

In fact, the description which the Nagell-Lutz theorem gives tells us that, if our curve has integer coefficients, then all of it's rational torsion points must have integer coefficients; ie if $T$ is the torsion subgroup then $T \subseteq C(Z)$. This is a strange and surprising result, and until we go through some of the basic lemmas of the proof, it is hard to intuitively explain why we would expect this to be the case. One thing we can see is that the complexity measure of height won't work for our proof: it is impossible to take $h(r)$ for some rational number $r \in Q$ and determine whether or not $r$ is an integer. At first, this may not seem like a big deal, however we will see later that it is not tricky to protectively transform \emph{any} elliptic curve into an elliptic curve with integer coordinates, and therefore by extension, \emph{any} cubic curve into an elliptic curve with integer coordinates.\\

The for some rational $r \in Q$ p-adic order of $r$, $ord_p(r)$ is defined as the value of the power of the prime $p$ when $p$ is completely "factored out" of $r$; ie, we can uniquely write:\\

$r = \frac{m}{n}p^v$ such that $p$, $m$ and $n$ are all coprime integers, then $ord_p(r) = v$\\

by convention, we define $ord_p(0) = \infty$ as in a sense $p$ divides $0$ infinitely\\

Knowledge of p-adic numbers is not necessary to understand the proof, however it does add to the intuitions one may have. This complexity measure has the nice property that $r$ is an integer if and only if $ord_p(r) \geq 0$ for all primes $p$, making it more suitable for the theorem that we are going to prove. \\

There are some other nice facts about p-adic order that one can mentally verify:\\

for all $q, r \in Q$:\\

- $ord_p(qr) = ord_p(q) + ord_p(r)$\\

- if $ord_p(q) = ord_p(r)$ then $ord_p(q + r)  \geq ord_p(q)$ or $ord_p(r)$\\

- if $ord_p(q) > ord_p(r)$ then $ord_p(q + r) = ord_p(r)$\\

- in general, $ord_p(q + r) \geq min(ord_p(q)$, $ord_p(r))$\\

We still don't have a measure that we can apply to points on $C(Q)$ just yet, but we can use these facts to prove a theorem about integer-coefficiented polynomials:\\

if $f(x) = x^n + c_{n-1}x^{n-1} + c_{n-2}x^{n-2} + \dots c_1 x + c_0$ is an integer coefficiented-polynomial, then for all $x \in Q$ with $ord_p(x) < 0$: $ord_p(f(x)) = n \ ord_p(x)$\\

The proof is relatively simple:

first, note that $ord_p(c_k x^k) = ord_p(c_k) + k \ ord_p(x)$ and that, as $f$ has integer coefficients, $ord_p(c_k) \geq 0$ hence $ord_p(c_k x^k) \geq k \ ord_p(x)$. However, as $ord_p(x) < 0$, $k \ ord_p(x) > n \ ord_p(x)$ for $k > n$. Hence we can see that $ord_p(c_k x^k) > ord_p(x^n)$ so our $x^n$ term will "eat" all the terms to the right of it:

\[ ord_p(x^n) = ord_p(x^n + c_{n-1}x^{n-1}) = ord_p(x^n + c_{n-1}x^{n-1} + c_{n-2}x^{n-2}) = \dots = ord_p(f(x)) \]


Thinking about this with respect to elliptic curves naturally leads us to the following corollary:\\

Let $C$ be an elliptic curve defined by $y^2 = f(x)$ for some integer coefficiented cubic $f$; Then, for all points $P = (x_P, y_P) \in C(Q)$ and all primes p; either:\\

\[ ord_p(x_P) \geq 0 \quad \text{and} \quad  ord_p(y_P) \geq 0 \]

\[ \text{or} \quad  2 \ ord_p(y_P) = 3 \ ord_p(x_P) \]

This is not too tricky to see:\\

if \quad $ord_p(y_P) < 0$ \quad then \quad $ord_p(f(x_P)) < 0$ \quad so \quad $ord_p(x_P) < 0$

and if \quad $ord_p(x_P) < 0$ \quad then \quad $3 \ ord_p(x_P) = ord_p(f(x_P)) = ord_p(y_P^2) = 2 \ ord_p(y_P)$\\

Hence, if $ord_p(x_P) < 0$ or $ord_p(y_P) < 0$ we should be able to find an integer $v > 0$ such that: $ord_p(x_P) = -2v$ and $ord_p(y_P) = -3v$\\

Applying this with all primes p tells us that $x_P$ and $y_P$ are of the form:\\

$x_P = \frac{m}{e^2}$ \quad and \quad $y_P = \frac{n}{e^3}$ for some integers $m$, $n$ and $e$\\

One way of defining a complexity measure for our points in $C(Q)$ for a given prime $p$ could be to say that $Complexity_p(P) = v$ where $v$ is the integer such that:  $ord_p(x_P) = -2v$ and $ord_p(y_P) = -3v$. We also need to extend this to points with that $ord_p(x_P) \geq 0$ and $ord_p(y_P) \geq 0$. To do this, we define $t(P) = \frac{x_P}{y_P}$ then we see that, using the definition of $v$ above, $ord_p(t(P)) = ord_p(x_p) - ord_p(y_P) = v$. \\ 

Unfortunately, we will see later that just by examining $t(P)$ it is impossible to tell if a point $P$ has integer coordinates. In order to have some way to keep track of this, we define subsets of points than have more than $2v$ or $3v$ factors of $p$ in their $x$ and $y$ coordinate's denominators:

\[ C(p^v) = \{(x, y) \in C(Q) \ | \ ord_p(x) \ \leq \ -2v \ \text{and} \ ord_p(y) \ \leq \ -3v\} \]

Then, to prove that a given point $P$ has integer coordinates, we just need to prove $P \notin C(p)$ for all primes $p$.\\

Note that $P \in C(p^v)$ implies $ord_p(t(P)) \geq v$ but not the other way round; take for instance this case where $p = 2$:\\

$P = (2, 3)$ is on the curve $y^2 = x^3 - x + 3$ and we can see $ord_2(t(P)) = ord_2(\frac{2}{3}) = 1$ but $P \notin C(2^1)$ \\

Now, given that both our $t$ function and our addition formula are defined completely algebraically over our sets of points, it makes sense that we may get some useful results from studying how they interact.

\subsection{Investigating the p-adic order of P + Q}

For this section, we will fix a certain prime $p$.

Let R be the ring of rational numbers with p-adic order greater than or equal to 0 (ie, the rationals which have powers of p only in their numerator if at all):

\[ R = \{r \in Q \; | \; ord_p(r) \geq 0\} \]

We can see that the units (elements in R with multiplicative inverses in R) are precisely the rationals with p-adic order 0. We can also see that the ideals of $R$ generated by $p^v$ for some $v$ are precisely the sets of rational numbers with p-adic order greater than than or equal to $v$:

\[ p^vR = \{r \in Q \; | \; ord_p(r) \geq v\} \]

Let $P$ and $Q$ both be in $C(p^v)$ for some $v$. We wish to study the p-adic order of the coordinates of $P + Q$ to see if we get anything interesting. As we saw in section 4.2, it is fruitful to define $t(P) = \frac{x_P}{y_P}$. We can see that we can actually make this value into a coordinate of P after applying a projective transformation $(x, y) \mapsto (t, s)$ given by:

\[ t = \frac{x}{y} \ \text{and} \ s = \frac{1}{y} \]

The important thing to note here is that $P \in C(p^v)$ iff $t_P \in p^v R$ and $s_P \in p^{3v} R$; so this transformation doesn't loose any information about whether or not $P$ is in $C(p^v)$\\

This transformation is it's own inverse, so $x$ and $y$ are given by:

\[ x = \frac{t}{s}, y = \frac{1}{s} \]

Plugging these into our curve's equation gives:

\[ \frac{1}{s^2} = \frac{t^3}{s^3} + a \frac{t^2}{s^2} + b \frac{t}{s} + c \]

hence:

\[ s = t^3 + a t^2 s + b t s^2 + c s^3 \]

Now, to add $(t_P, s_P)$ and $(t_Q, s_Q)$ on our curve we simply follow the procedure for a standard cubic curve.\\

First, we find the line going through $t_P$ and $t_Q$:

\[ s = \alpha t + \beta \quad \text{with} \quad \alpha = \frac{s_P - s_Q}{t_P - t_Q} \text{and} \beta = s_P - \alpha t_P \]

Then, we simultaneously solve the line equation and the curve equation to find the third intersection point:

\[ \alpha t + \beta = t^3 + a t^2 (\alpha t + \beta) + b t (\alpha t + \beta)^2 + c (\alpha t + \beta)^3 \]

Collecting terms gives:

\[ 0 = k_3 t^3 + k_2 t^2 + k_1 t + k_0 \]

where $k_3 = 1 + a \alpha + b \alpha^2 + c \alpha^3$ and $k_2 = a \beta + + 2 b \alpha \beta + 3c \alpha^2 \beta$\\

hence: 

\[ t_P + t_Q + t_{P*Q} = -\frac{k_2}{k_3} \]

Note that in our projective transformation the zero point was mapped to the origin and our curve is symmetric about the line $t + s = 0$ as if $(t, s)$ is on our curve then $(-t, -s)$ will also be on our curve. Combining these pieces of information, it is not too tricky to see that $(t_{P + Q}, s_{P + Q}) = (-t_{P * Q}, -s_{P * Q})$, hence we have that:

\[ t_P + t_Q - t_{P+Q} = -\frac{k_2}{k_3} \]

After this rather laborious bit of algebra, we can see a few things pop out at us: namely, if we can prove that $-\frac{k_2}{k_3} \in p^v R$ then we can prove that $t_{P+Q} \in p^v R$, strongly suggesting that $C(p^v)$ is a subgroup. Unfortunately, to get more information about $-\frac{k_2}{k_3}$ we must first go back and examine $\alpha$ and $\beta$. \\

As $s_P$ and $s_Q$ are in $p^{3v}R$ and $t_P$ and $t_Q$ are only in $p^v R$ it seems intuitive that $\alpha \in p^{2v}R$, however the preceding information alone doesn't give us enough information to \emph{prove} this. We need to also use the information that links $s_P$ with $t_P$ and $s_Q$ with $t_Q$; namely that they satisfy the cubic equation for our curve. Examining the top part of our fraction for $\alpha$, $s_P - s_Q$, gives:

\begin{align*} 
s_P - s_Q &= t_P^3 - t_Q^3 + a \; t_P^2 s_P - a \; t_P^2 s_P + b \; t_P s_P^2 - b \; t_Q s_Q^2 + c \; s_p^3 - c \; s_Q^3 \\
&= t_P^3 - t_Q^3 \\
& \quad + a(t_P^2 s_P - t_P^2 s_Q + t_P^2 s_Q - t_Q^2 s_Q) \\
& \quad + b(t_P s_P^2 - t_Q s_P^2 + t_Q s_P^2 - t_Q s_Q^2) \\
& \quad + c(s_P^3 - s_Q^3) \\
&= (t_P - t_Q)(t_P^2 + t_P t_Q + t_Q^2) \\
& \quad + a(s_P - s_Q)t_P^2 + a(t_P - t_Q)(t_P + t_Q)s_Q \\
& \quad + b(t_P - t_Q)s_P^2 + b(s_P - s_Q)(s_P + s_Q)t_Q \\
& \quad + c(s_P - s_Q)(s_P^2 + s_P s_Q + s_Q ^2)
\end{align*} 


Factoring out $s_P - s_Q$ and $t_P - t_Q$ gives:

\[(1 - A)(s_P - s_Q) = B(t_P - t_Q)\]
where 
\[A = a t_P^2 + b(s_P + s_Q)t_Q + c(s_P ^2 s_p s_Q + s_Q^2) 
\quad \text{and} \quad
B = (t_P^2 + t_P t_Q + t_Q^2) + a (t_P + t_Q)s_Q + b s_p^2\]

Hence: 

\[ \alpha = \frac{s_P - s_Q}{t_P - t_Q} = \frac{B}{1 - A} \]

Now, we can see that $B \in p^{2v}R$ and $A \in p^{2v} R$ from the fact that they are the sums of terms in these ideals. Hence, $ord_p(A) \geq 2v \geq 0 = ord_p(1)$ so $ord_p(1 - A) = 0$. Hence $1 - A$ is a unit in $R$ so $\frac{1}{1 - A} \in R$, meaning that we can conclude $\alpha = \frac{B}{1 - A} \in p^{2v}R$ \\

Now, going back to our formulas for $k_3$ and $k_2$ we see that and applying similar reasoning, $k_2 \in p^{3v}R$ and $\frac{1}{k_3} \in R$ so $\frac{k_2}{k_3} \in p^{3v}R$. This finally allows us to see that:

\[ t_P + t_Q - t_{P+Q} \in p^{3v}R \]

Written in modular arithmetic notation, this becomes even more suggestive that this is something that will be useful in our proof: 

\[ t_P + t_Q  \equiv t_{P+Q} \quad (\bmod{p^{3v}R}) \]

This shows that $t_{P+Q} \in p^{v}R$ but doesn't on it's own doesn't show that $P + Q \in C(p^v)$, we also have to show that $s_{P + Q} \in p^{3v}R$. This isn't too tricky; as $P*Q$ is on the same line as $P$ and $Q$:\\

\[s_{P*Q} = \alpha t_{P*Q} + \beta \in p^{3v}R \quad \ \text{ as } \ t_{P+Q}, \ \alpha \ \text{ and } \ \beta \ \text{ are in } \ p^v R, \ p^{2v} R \ \text{ and } \ p^{3v} R  \text{ respectively} \]

Hence, we also have that $s_{P+Q} = -s_{P*Q} \in p^v R$, so our set of points $C(p^v)$ is closed under addition of points. In fact, as $P*Q = - (P+Q)$ and we have also in the process shown $P*Q \in C(p^v)$, $C(p^v)$ is a subgroup of $C(Q)$. \\

To summarise the two main findings of our investigation:\\

- We have a series of of subgroups of rational points given by: $C(Q) \supseteq C(p) \supseteq C(p^2) \supseteq C(p^3) \dots$\\

- if $t_P$ and $t_Q$ are in $p^v R$ for some $v$, then: $t_P + t_Q  \equiv t_{P+Q} \quad (\bmod{p^{3v}R})$

\subsection{Finishing off the Nagell-Lutz proof}

Let $p$ be any prime number\\

Let $P \in C(Q)$ be a point of order $m$ with $m \neq 1$. We will show $P \notin C(p)$ \\

First, we need to factor most (or all) of the powers of $p$ in $m$ so that they don't interfere with our proof (We will see later why this is necessary).\\

It is not hard to see that for any $m \neq 1$ we can find a $\bar{m} \neq 1$ that divides $m$ and has at most one factor of $p$. For instance, if $m$ has no factors of $p$ we can pick $\bar{m} = m$ and otherwise we can pick $\bar{m} = \frac{m}{p^k}$

Now, let $P' = \frac{m}{\bar{m}} P$. We can see it suffices to prove $P' \notin C(p)$ as $C(p)$ is a subgroup\\

Let $v$ be the unique natural number such that: $P' \in C(p^v)$ but $P' \notin C(p^{v+1})$ \\

if $v = 0$, we are done as $P' \notin C(p)$. Hence we are restricted to examining the case where $v > 0$, and in this case we can deduce that $ord_p(t(P')) = v$ Now, we can examine $P'$ using the congruence relation:

\begin{align*}
    \text{first, note; } \quad & t(\bar{m}P') = t(mP) = t(0) = 0 \\
    \text{Hence, } \quad & \bar{m}t(P') \equiv t(\bar{m}P') \equiv 0 \quad (\bmod{p^{3v}R}) \\
    \text{Hence } \quad & \bar{m}t(P') \in p^{3v}R \\
\end{align*}

Now we see why we chose to examine $P'$ rather than $P$: if we got to this stage with $P$, we would not be able to say much in general as the number in front of $t(P)$ could be arbitrarily divisible by $p$, However, as $\bar{m}$ has at most one factor of p, we can say:

\begin{align*}
    & t(P') \in p^{3v-1}R\\
    \text{hence :} \quad & ord_p(t(P)) \geq 3v - 1 \\
    \text{however, we know :} \quad & ord_p(t(P)) = v\\
    \text{hence: } \quad & v \geq 3v - 1
\end{align*}

So we are forced to conclude $v = 0$, which is a contradiction as we were restricted to the case $v > 0$.

Hence, for all points of finite order $P$ with $mP = 0$; either:

- $m = 1$ in which case $P = 0$

- $m \neq 1$ in which case $P \notin C(p)$ for all primes $p$, so $P$ must have integer coordinates

\subsection{Further constricting the set of torsion candidates}

Let $P \neq 0$ be a point of finite order. We have proved that if $(x, y) = P$ then $x$ and $y$ must be integers; however this unfortunately still gives us an infinite search space of possible candidates of points that could be torsion points on the curve. Thankfully, it is not too tricky to restrict this set to a finite set.\\

First, we know that as $P$ is on the curve with integer coordinates, 

\[ y^2 = f(x) = x^3 + a x^2 + b x + c \]

equivalently,

\[ y^2 - c = x(x^2 + a x + b) \]

Hence, we can see that for any candidate $y$, $x$ must divide $y^2 - c$ to give an integer point on the curve. So all we need to find is a finite set of candidate $y$ values; which is described by the following lemma:\\

If $P = (x, y)$ is a point of finite order then $y$ divides the discriminant of $f$ or $y = 0$\\

There may be other restrictions that we can place on $y$, but this one turns out to be the easiest. First, note that if $P$ is of order one then $P = 0$ and if $P$ is of order two, then $P = -P$ which can only be the case if $y = 0$. Hence, we can restrict our search to the points where $P$ and $2P$ are both non-zero points of finite order (and hence both have integer coordinates).

\begin{align*}
    \text{Let } \quad & 2P = (x_2, y_2)\\
    \text{then, we have: } \quad & x_2 = \left( \frac{f'(x)}{2y} \right) ^2 - 2x - a\\
    \text{hence: } \quad & \left( \frac{f'(x)}{2y} \right) ^2 = x_2 + 2x + a \in Z\\
\end{align*}

However, we know that, as $\frac{f'(x)}{2y} \in Q$, it must be the case that $\frac{f'(x)}{2y} \in Z$ as non-integer rational can never be squared to give an integer. Hence, $y$ divides $f'(x)$. However, we also know that $y$ divides $f(x)$ from our Weierstrass equation. We can combine these two facts put a restriction on $y$. Now, consider the ideal in $Z[x]$ generated by $f$ and $f'$ (call it $I = <f, f'>$).\\

If there is an integer $n \in I$, then we can conclude that we can find polynomials $G_1$ and $G_2$ in $Z[x]$ such that, for all $x$:

\[ n = G_1(x)f(x) + G_2(x)f'(x) \]

Note that $n$ does not vary with respect to $x$, so if we could find such an $n$, then we know that \emph{every} $y$-coordinate for a point of finite order must divide this $n$, as \emph{every} $y$-coordinate for a point of finite order divides both $f(x)$ and $f'(x)$ for some integer $x$.\\

Thankfully, using the theory of resultants and discriminants, we can prove that it suffices to set $n = \Delta(f)$, where $\Delta(f) = -4a^3c + a^2b^2 + 18abc - 4b^3 - 27c^2$ is the discriminant of f. We have that if $A(x)$ and $B(x)$ are two polynomials in $Z[x]$, then the resultant $Res(A, B)$ (an integer quantity calculated by taking the determinant of a specific matrix of $A$ and $B$'s coefficients) is in the ideal generated by $A$ and $B$. In the case where $A$ and $B$ are $f$ and $f'$ for some polynomial $f$, The resultant divided by the leading coefficient of $f$ (which in our case is one) is simply the discriminant of $f$: \\

\[ Res(f, f') = \Delta(f) \]

Hence, we can see that $\Delta(f) \in I$. So for any point with integer coordinates $P = (x, y)$ where $2P$ also has integer coordinates, we can see that $y$ must divide $\Delta(f)$, concluding our proof.


\subsection{An algorithm for generating the set of torsion points}

In the previous section, we looked at restricting the set of possible torsion points to a finite set, so that we could then test these points individually to see if they are actually of finite order or not. We will now go through an example of this, computing the torsion points of the curve:

\[y^2 = f(x) = x^3 - 43 x + 166\]

First, we want to calculate the discriminant to find our $y$ candidates:

\[\Delta(f) =  -4 \times 0^3 \times 166 + 0^2 \times (-43)^2 + 18 \times 0 \times (-43) \times 166 - 4 \times (-43)^3 - 27 \times (166)^2 = -425984\]

From this, we get a long list of candidate $y$ values, consisting of 0 and every value that divides the discriminant (thankfully, it is not too tricky to just print this out with Python):\\

[0, 1, -1, 2, -2, 4, -4, 8, -8, 13, -13, 16, -16, 26, -26, 32, -32, 52, -52, 64, -64, 104, -104, 128, -128, 208, -208, 256, -256, 416, -416, 512, -512, 832, -832, 1024, -1024, 1664, -1664, 2048, -2048, 3328, -3328, 4096, -4096, 6656, -6656, 8192, -8192, 13312, -13312, 16384, -16384, 26624, -26624, 32768, -32768, 53248, -53248, 106496, -106496, 212992, -212992, 425984, -425984]\\

Then, all we need to do for each candidate $y$ value is to loop through the $x$ values which divide $y^2 - 166$ and see if any of them are on the curve. For example, for the candidate $y$ value of $16$, $y^2 - 166 = 90$, so our list of candidate $x$ values is : [1, -1, 2, -2, 3, -3, 5, -5, 6, -6, 9, -9, 10, -10, 15, -15, 18, -18, 30, -30, 45, -45, 90, -90] If we check each of these candidate x values with y = 16 to see if they are points on the curve, we see that we eventually get the point (-5, 16). Repeating this process for all the candidate $y$ values eventually  gives just six candidate points:

\[(3, \pm 8), \quad (11, \pm 32) \quad \text{and} \quad (-5, \pm 16)\]

The Nagell-Lutz theorem tells us that this set of candidates contains all the torsion points, but it does not guarantee that all these points are torsion points. Testing these points to see if they are actually torsion points eventually leads us to see that they are all, in fact, of finite order, and our torsion subgroup is isomorphic to the cyclic group of order $7$. To do this, we simply pick one of our points say, $P = (11, 32)$, and see that:

\begin{align*} 
P &= (11, 32)\\
2P &= (3, 8)\\
3P &= (-5, 16)\\
4P &= (-5, -16)\\
5P &= (3, -8)\\
6P &= (11, -32)\\
7P &= 0
\end{align*} 

If any of the points in this list, say $kP$ for some $k$ didn't turn out to be in our set of torsion candidates, we would be able to deduce that this $kP$ is not a torsion point. Further, as our torsion points are a subgroup, we would be able to deduce that $P$ and hence all points on this list would not be torsion points and can therefore be discarded. As our set of candidate points is finite, we can conclude that our sequence of points $P, 2P, 3P \dots$ must eventually either a) go out of this set which we have seen meens we can discard the list or b) re-visit points, which can only be the case if $mP = 0$ for some $P$, in which case we can say that every point on this list of points is a torsion point; so we can see that our algorithm for doing this will \emph{eventually} halt.\\

Barry Mazur (quoted in the beginning) proved in 1978 that there are only a few possible torsion subgroups that our elliptic curve can have; all being of order less than 12. This means that, at most, have to check $P, 2P, ... 12P$ to see if $P$ is of finite order.

\newpage

\section{Some examples to get started}

\subsection{How to create Sections and Subsections}

Simply use the section and subsection commands, as in this example document! With Overleaf, all the formatting and numbering is handled automatically according to the template you've chosen. If you're using Rich Text mode, you can also create new section and subsections via the buttons in the editor toolbar.

\subsection{How to include Figures}

First you have to upload the image file from your computer using the upload link in the file-tree menu. Then use the include graphics command to include it in your document. Use the figure environment and the caption command to add a number and a caption to your figure. See the code for Figure \ref{fig:frog} in this section for an example.

Note that your figure will automatically be placed in the most appropriate place for it, given the surrounding text and taking into account other figures or tables that may be close by. You can find out more about adding images to your documents in this help article on \href{https://www.overleaf.com/learn/how-to/Including_images_on_Overleaf}{including images on Overleaf}.
\newpage
\begin{figure}
\centering
\includegraphics[width=0.3\textwidth]{frog.jpg}
\caption{\label{fig:frog}This frog was uploaded via the file-tree menu.}
\end{figure}

\subsection{How to add Tables}

Use the table and tabular environments for basic tables --- see Table~\ref{tab:widgets}, for example. For more information, please see this help article on \href{https://www.overleaf.com/learn/latex/tables}{tables}. 

\begin{table}
\centering
\begin{tabular}{l|r}
Item & Quantity \\\hline
Widgets & 42 \\
Gadgets & 13
\end{tabular}
\caption{\label{tab:widgets}An example table.}
\end{table}

\subsection{How to add Comments and Track Changes}

Comments can be added to your project by highlighting some text and clicking ``Add comment'' in the top right of the editor pane. To view existing comments, click on the Review menu in the toolbar above. To reply to a comment, click on the Reply button in the lower right corner of the comment. You can close the Review pane by clicking its name on the toolbar when you're done reviewing for the time being.

Track changes are available on all our \href{https://www.overleaf.com/user/subscription/plans}{premium plans}, and can be toggled on or off using the option at the top of the Review pane. Track changes allow you to keep track of every change made to the document, along with the person making the change. 

\subsection{How to add Lists}

You can make lists with automatic numbering \dots

\begin{enumerate}
\item Like this,
\item and like this.
\end{enumerate}
\dots or bullet points \dots
\begin{itemize}
\item Like this,
\item and like this.
\end{itemize}

\subsection{How to write Mathematics}

\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
\[S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
      = \frac{1}{n}\sum_{i}^{n} X_i\]
denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.


\subsection{How to change the margins and paper size}

Usually the template you're using will have the page margins and paper size set correctly for that use-case. For example, if you're using a journal article template provided by the journal publisher, that template will be formatted according to their requirements. In these cases, it's best not to alter the margins directly.

If however you're using a more general template, such as this one, and would like to alter the margins, a common way to do so is via the geometry package. You can find the geometry package loaded in the preamble at the top of this example file, and if you'd like to learn more about how to adjust the settings, please visit this help article on \href{https://www.overleaf.com/learn/latex/page_size_and_margins}{page size and margins}.

\subsection{How to change the document language and spell check settings}

Overleaf supports many different languages, including multiple different languages within one document. 

To configure the document language, simply edit the option provided to the babel package in the preamble at the top of this example project. To learn more about the different options, please visit this help article on \href{https://www.overleaf.com/learn/latex/International_language_support}{international language support}.

To change the spell check language, simply open the Overleaf menu at the top left of the editor window, scroll down to the spell check setting, and adjust accordingly.

\subsection{How to add Citations and a References List}

You can simply upload a \verb|.bib| file containing your BibTeX entries, created with a tool such as JabRef. You can then cite entries from it, like this: \cite{greenwade93}. Just remember to specify a bibliography style, as well as the filename of the \verb|.bib|. You can find a \href{https://www.overleaf.com/help/97-how-to-include-a-bibliography-using-bibtex}{video tutorial here} to learn more about BibTeX.

If you have an \href{https://www.overleaf.com/user/subscription/plans}{upgraded account}, you can also import your Mendeley or Zotero library directly as a \verb|.bib| file, via the upload menu in the file-tree.

\subsection{Good luck!}

We hope you find Overleaf useful, and do take a look at our \href{https://www.overleaf.com/learn}{help library} for more tutorials and user guides! Please also let us know if you have any feedback using the Contact Us link at the bottom of the Overleaf menu --- or use the contact form at \url{https://www.overleaf.com/contact}.

\bibliographystyle{alpha}
\bibliography{sample}

\end{document}